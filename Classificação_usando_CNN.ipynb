{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laccar1109/Classifica-o_usando_CNN.ipynb/blob/main/Classifica%C3%A7%C3%A3o_usando_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN - Distinguindo os diversos tipos de arroz integral\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ezeWLQu2k9GS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Importando as Bibliotecas"
      ],
      "metadata": {
        "id": "Jo-BzdtxRed_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wogJKlL0l1-9",
        "outputId": "6e010d68-2a4b-4d87-e858-8b28fb6c676c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.8/dist-packages (from rasterio) (1.21.6)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.8/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from rasterio) (22.2.0)\n",
            "Collecting affine\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from rasterio) (2022.12.7)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.8/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.4 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Importando o dataset"
      ],
      "metadata": {
        "id": "I5mL6SHKMa48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aE9O3CgT-y-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f20131-3b9d-408f-9e2c-f15404dd3cb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Importando as Bibliotecas"
      ],
      "metadata": {
        "id": "2CKjw9mQW8Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import matplotlib\n",
        "import imageio\n",
        "\n",
        "#Importar biblioteca para visaulizar dados\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "\n",
        "#Importar Tensorflow para criar modelos e dependencias\n",
        "import tensorflow\n",
        "\n",
        "#Gerar lotes de dados de imagem de tensor com aumento de dados em tempo real.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "#Para ativar a plotagem em linha\n",
        "%matplotlib  inline "
      ],
      "metadata": {
        "id": "8xsK8tDUsp9y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 2.Imagem Pre-processada"
      ],
      "metadata": {
        "id": "wLzGHDloS9QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reconhecimento de tipos de graos de arroz usando modelo de CNN\n",
        "''' Esse script usa database de imagens criado por um modelo CNN acima para testar se reconhece a imagem correctamente ou nao'''\n",
        "\n",
        "'''#################### IMAGEM PRE- PROCESSADA PARA TREINAMENTO E TESTE O BANCO ####################'''\n",
        "\n",
        "TrainingImagePath ='/content/drive/MyDrive/Image Classification/train'\n",
        "TestingImagePath = '/content/drive/MyDrive/Image Classification/test'\n",
        "ValidationImagePath = '/content/drive/MyDrive/Image Classification/valid'\n",
        "\n",
        "# Defining pre-processing transformations on raw images of training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "# Defining pre-processing transformations on raw images of testing data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generating the Training Data\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "# Generating the Testing Data\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        TestingImagePath,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Generating the Testing Data\n",
        "valid_set = test_datagen.flow_from_directory(\n",
        "        ValidationImagePath,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "Bv3nLE-UvvZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ddc4ab3-5cc6-4ca7-e9f4-96f1eaa82016"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 525 images belonging to 5 classes.\n",
            "Found 175 images belonging to 5 classes.\n",
            "Found 175 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Função para plotar"
      ],
      "metadata": {
        "id": "sU-I4gDFMHrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# função para plotar qualquer imagem aleatória do conjunto de dados\n",
        "def showImages(class_name):\n",
        "    random_index = random.choice(list(range(5, 5)))\n",
        "    folder_path=os.path.join(TrainingImagePath, class_name)\n",
        "    try:\n",
        "        image_path=os.path.join(folder_path,str(random_index).zfill(3)+\".jpg\")\n",
        "        plt.imshow(mpimg.imread(image_path))\n",
        "    except:\n",
        "        image_path=os.path.join(folder_path,str(random_index).zfill(2)+\".jpg\")\n",
        "        plt.imshow(mpimg.imread(image_path))\n",
        "    plt.title(class_name)\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "id": "NsnbgrhbXRHc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 As 5 layers"
      ],
      "metadata": {
        "id": "5HZG-zw8Wmoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar as classes e faces de cada grao\n",
        "test_set.class_indices"
      ],
      "metadata": {
        "id": "-YRrTJMYBo7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86e6b62-9a4a-4339-adfb-249c3d3bf77b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Arborio': 0, 'Basmati': 1, 'Ipsala': 2, 'Jasmine': 3, 'Karacadag': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.0 Plotar Graficos"
      ],
      "metadata": {
        "id": "d4hv_1WpbWul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (20, 20))\n",
        "for labels, number in training_set.class_indices.items ():  \n",
        "    plt.subplot (5, 5, number+1) \n",
        "    showImages (labels)"
      ],
      "metadata": {
        "id": "MLDtv0IRhwWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "cf6818d9-405a-4556-8c1a-d8aa37d02d23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a4a94e12bada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mshowImages\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2bb306fa91f2>\u001b[0m in \u001b[0;36mshowImages\u001b[0;34m(class_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# função para plotar qualquer imagem aleatória do conjunto de dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshowImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrandom_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.1  Criando tabela de consulta para mostrar"
      ],
      "metadata": {
        "id": "4G2uZct7bm8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''####################Criando tabela de consulta para mostrar os diferentes grãos de arroz####################'''\n",
        "# índices de classe têm a etiqueta numérica para cada grãos de arroz\n",
        "TrainClasses=test_set.class_indices\n",
        "\n",
        "#Armazenando a imagem e o numérica para referência futura\n",
        "ResultMap=[]\n",
        "for arrozValue, arrozName in (TrainClasses.values(), TrainClasses.Keys()):\n",
        "ResultMap (arrozValues)= arrozName\n",
        "\n",
        "# Guardar a o caminho da imagem para referência futura\n",
        "\n",
        "import pickle as pkl\n",
        "with open ('/content/drive/MyDrive/Image Classification/ResultMap.pkl', 'wb') as f:\n",
        "    pickle.dump(ResultMap, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"Mapeando o arroz e o seu ID\", ResultMap)    \n",
        "\n",
        "# O número de neurônios para a camada de Output é igual ao número de imagens \n",
        "OutputNeurons = len( ResultMap)\n",
        "print('\\n The Number of output neurons: ', OutputNeurons)\n",
        "\n",
        "Mapping of Face and its ID \n",
        "{ 0:'Arborio', 1:'Basmati', 2:'Ipsala', 3: 'Jasmine', 4: 'Karacadag'}\n",
        "The number of output neurons: 13"
      ],
      "metadata": {
        "id": "VFx13d_kgcQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "with open ('/content/drive/MyDrive/Image Classification/ResultMap.pkl', 'wb') as f:\n",
        "    pickle.dump(ResultMap, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "P6-LzoqmXLVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criar lista de arroz e classe"
      ],
      "metadata": {
        "id": "yqE4W53JgdtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''#################### Criar um modelo de aprendizado profundo usando CNN ####################'''\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "'''Incilizacao da Rede Neural Convolucional'''\n",
        "classifier = Sequential() \n",
        "\n",
        "\n",
        "'''STEP--1 Convolution\n",
        "# Adicionar a primeira Layer de CNN\n",
        "# Usaremos o format (64, 64, 3) pois usaremos o Tensorflow backend\n",
        "#Resultara em 3 matrizes de tamanho (64X64) pixels representando (RGB) vermelho, verde e azul componentes de pixels\n",
        "'''\n",
        "classifier.add(Convolution2D(32,kernel_size=(3,3), strides=(1, 1), activation= 'relu'))\n",
        "\n",
        "\n",
        "'''# STEP--2 MAX Pooling '''\n",
        "classifier.add(MaxPool2D(pool_size= ( 2,2)))\n",
        "\n",
        "'''############## ADDITIONAL LAYER of CONVOLUTION for better accuracy #################'''\n",
        "classifier.add(Convolution2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
        "\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "'''# STEP--3 FLattening'''\n",
        "classifier.add(Flatten())\n",
        "\n",
        "'''# STEP--4 Fully Connected Neural Network'''\n",
        "classifier.add(Dense(256, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
        "\n",
        "'''# Compiling the CNN'''\n",
        "#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer = 'rmsprop', metrics=[\"accuracy\"])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e9m1DAq0AnDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# Measuring the time taken by the model to train\n",
        "StartTime=time.time()\n",
        "\n",
        "# Starting the model training\n",
        "model_history=classifier.fit_generator(\n",
        "                                        training_set,\n",
        "                                        steps_per_epoch=len(training_set),\n",
        "                                        epochs=20,\n",
        "                                        validation_data=valid_set,\n",
        "                                        validation_steps=len(valid_set),\n",
        "                                        verbose=1)\n",
        "\n",
        "EndTime=time.time()\n",
        "print(\"############### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes #############')"
      ],
      "metadata": {
        "id": "dYq_LA5qPKG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model_history.history['accuracy']\n",
        "val_accuracy  = model_history.history['val_accuracy']\n",
        "\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']"
      ],
      "metadata": {
        "id": "nUpb6LPUP9Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickleshare import pickle"
      ],
      "metadata": {
        "id": "vvf4fNbWfB2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(accuracy, label = \"Training accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation accuracy\")\n",
        "\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(loss, label = \"Training loss\")\n",
        "plt.plot(val_loss, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training vs validation loss\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "51zisjtmQLyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Saving the model\n",
        "classifier.save(\"/content/drive/MyDrive/Image Classification/train/classifier.pkl\")"
      ],
      "metadata": {
        "id": "9HPzEQIzQUCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''########################## Making single predictions ############################'''\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "testImage=\"/content/drive/MyDrive/Image Classification/test/Arborio/Arborio (1).jpg\"\n",
        "test_image=load_img(testImage,target_size=(128, 128))\n",
        "test_image=img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=classifier.predict(test_image,verbose=0)\n",
        "\n",
        "img = cv2.imread(testImage)\n",
        "# gray = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title('picture')\n",
        "plt.show()\n",
        "\n",
        "print('####'*10)\n",
        "print('Prediction is: ',ResultMap[np.argmax(result)])"
      ],
      "metadata": {
        "id": "yt3xYAfgQ0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''########################## Making single predictions ############################'''\n",
        "testImage=\"/content/drive/MyDrive/Image Classification/test/Basmati/basmati (12).jpg\"\n",
        "test_image=load_img(testImage,target_size=(128, 128))\n",
        "test_image=img_to_array(test_image)\n",
        "\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=classifier.predict(test_image,verbose=0)\n",
        "\n",
        "img = cv2.imread(testImage)\n",
        "# gray = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title('picture')\n",
        "plt.show()\n",
        "\n",
        "print('####'*10)\n",
        "print('Prediction is: ',ResultMap[np.argmax(result)])"
      ],
      "metadata": {
        "id": "zo1R_iTGR9Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando modelo CNN"
      ],
      "metadata": {
        "id": "Oni9IZ9hAoWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = matplotlib.pyplot.gcf()\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "fig.savefig('test2png.png', dpi=100)\n"
      ],
      "metadata": {
        "id": "oaCei0r_pGzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}